{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open and read input file\n",
    "with open(\"kendrick_lamar_lyrics.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    lyrics = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "554065"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check how many characters there are in the dataset\n",
    "len(lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sit still and close your eyes smoke to it\n",
      "what's behind the other door oh-ohh\n",
      "no more silence no more silence\n",
      "don't kill this thing we got called love don't shoot\n",
      "just searching for the perfect shot\n",
      "\n",
      "i used to write rhymes all day and all night\n",
      "when y'all was playing playstation, my pencil was erasing lines\n",
      "my conscience only knew what's half-tight\n",
      "at 3:14, it's time to get me a slice my nigga\n",
      "this is a dog's fight my nigga\n",
      "the soundtrack to life my nigga\n",
      "kendrick lamar, his momma called him that\n",
      "he watched house party and ate apple jacks\n",
      "he sold sega games, his cousin sold crack\n",
      "he pumped reeboks, his uncles pumped packs\n",
      "punk fake, jump-shot, ball hit the back\n",
      "ball dreams of being point guard was off limits jack\n",
      "that's because these compton streets was built not to win\n",
      "you killed the nigga, i stole a bible, is that a sin\n",
      "part of me though, i'm searching for answers just searching for the perfect shot\n",
      "the good kid from the ugly city that's mad that he's had some\n",
      "where is the love\n",
      "\n",
      "when\n"
     ]
    }
   ],
   "source": [
    "# take a look at the first 1000 characters\n",
    "print(lyrics[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !\"&'(),-./0123456789:?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyzàâãéíïúе– \n",
      "86\n"
     ]
    }
   ],
   "source": [
    "# check all the unique characters that occur in the dataset\n",
    "chars = sorted(list(set(lyrics)))\n",
    "vocab_size = len(chars)\n",
    "print(\"\".join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple tokeniser for the text/lyrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a mapping from characters to integers (encoder) and vice-versa (decoder)\n",
    "str_to_int = {char: i for i, char in enumerate(chars)}\n",
    "int_to_str = {i: char for i, char in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder takes a string which outputs a list of integers ,\n",
    "# characters in string are converted to int via lookup table\n",
    "encode = lambda s: [str_to_int[c] for c in s]\n",
    "\n",
    "# decoder takes a list of integers and outputs a string, integers converted via lookup table\n",
    "decode = lambda l: \"\".join([int_to_str[i] for i in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[57, 54, 61, 61, 64, 64, 1, 69, 57, 54, 67, 54]\n",
      "helloo there\n"
     ]
    }
   ],
   "source": [
    "print(encode(\"helloo there\"))\n",
    "print(decode(encode(\"helloo there\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([554065]) <built-in method type of Tensor object at 0x000001366FC0D370>\n",
      "tensor([68, 58, 69,  1, 68, 69, 58, 61, 61,  1, 50, 63, 53,  1, 52, 61, 64, 68,\n",
      "        54,  1, 74, 64, 70, 67,  1, 54, 74, 54, 68,  1, 68, 62, 64, 60, 54,  1,\n",
      "        69, 64,  1, 58, 69,  0, 72, 57, 50, 69,  5, 68,  1, 51, 54, 57, 58, 63,\n",
      "        53,  1, 69, 57, 54,  1, 64, 69, 57, 54, 67,  1, 53, 64, 64, 67,  1, 64,\n",
      "        57,  9, 64, 57, 57,  0, 63, 64,  1, 62, 64, 67, 54,  1, 68, 58, 61, 54,\n",
      "        63, 52, 54,  1, 63, 64,  1, 62, 64, 67, 54,  1, 68, 58, 61, 54, 63, 52,\n",
      "        54,  0, 53, 64, 63,  5, 69,  1, 60, 58, 61, 61,  1, 69, 57, 58, 68,  1,\n",
      "        69, 57, 58, 63, 56,  1, 72, 54,  1, 56, 64, 69,  1, 52, 50, 61, 61, 54,\n",
      "        53,  1, 61, 64, 71, 54,  1, 53, 64, 63,  5, 69,  1, 68, 57, 64, 64, 69,\n",
      "         0, 59, 70, 68, 69,  1, 68, 54, 50, 67, 52, 57, 58, 63, 56,  1, 55, 64,\n",
      "        67,  1, 69, 57, 54,  1, 65, 54, 67, 55, 54, 52, 69,  1, 68, 57, 64, 69,\n",
      "         0,  0, 58,  1, 70, 68, 54, 53,  1, 69, 64,  1, 72, 67, 58, 69, 54,  1,\n",
      "        67, 57, 74, 62, 54, 68,  1, 50, 61, 61,  1, 53, 50, 74,  1, 50, 63, 53,\n",
      "         1, 50, 61, 61,  1, 63, 58, 56, 57, 69,  0, 72, 57, 54, 63,  1, 74,  5,\n",
      "        50, 61, 61,  1, 72, 50, 68,  1, 65, 61, 50, 74, 58, 63, 56,  1, 65, 61,\n",
      "        50, 74, 68, 69, 50, 69, 58, 64, 63,  8,  1, 62, 74,  1, 65, 54, 63, 52,\n",
      "        58, 61,  1, 72, 50, 68,  1, 54, 67, 50, 68, 58, 63, 56,  1, 61, 58, 63,\n",
      "        54, 68,  0, 62, 74,  1, 52, 64, 63, 68, 52, 58, 54, 63, 52, 54,  1, 64,\n",
      "        63, 61, 74,  1, 60, 63, 54, 72,  1, 72, 57, 50, 69,  5, 68,  1, 57, 50,\n",
      "        61, 55,  9, 69, 58, 56, 57, 69,  0, 50, 69,  1, 15, 22, 13, 16,  8,  1,\n",
      "        58, 69,  5, 68,  1, 69, 58, 62, 54,  1, 69, 64,  1, 56, 54, 69,  1, 62,\n",
      "        54,  1, 50,  1, 68, 61, 58, 52, 54,  1, 62, 74,  1, 63, 58, 56, 56, 50,\n",
      "         0, 69, 57, 58, 68,  1, 58, 68,  1, 50,  1, 53, 64, 56,  5, 68,  1, 55,\n",
      "        58, 56, 57, 69,  1, 62, 74,  1, 63, 58, 56, 56, 50,  0, 69, 57, 54,  1,\n",
      "        68, 64, 70, 63, 53, 69, 67, 50, 52, 60,  1, 69, 64,  1, 61, 58, 55, 54,\n",
      "         1, 62, 74,  1, 63, 58, 56, 56, 50,  0, 60, 54, 63, 53, 67, 58, 52, 60,\n",
      "         1, 61, 50, 62, 50, 67,  8,  1, 57, 58, 68,  1, 62, 64, 62, 62, 50,  1,\n",
      "        52, 50, 61, 61, 54, 53,  1, 57, 58, 62,  1, 69, 57, 50, 69,  0, 57, 54,\n",
      "         1, 72, 50, 69, 52, 57, 54, 53,  1, 57, 64, 70, 68, 54,  1, 65, 50, 67,\n",
      "        69, 74,  1, 50, 63, 53,  1, 50, 69, 54,  1, 50, 65, 65, 61, 54,  1, 59,\n",
      "        50, 52, 60, 68,  0, 57, 54,  1, 68, 64, 61, 53,  1, 68, 54, 56, 50,  1,\n",
      "        56, 50, 62, 54, 68,  8,  1, 57, 58, 68,  1, 52, 64, 70, 68, 58, 63,  1,\n",
      "        68, 64, 61, 53,  1, 52, 67, 50, 52, 60,  0, 57, 54,  1, 65, 70, 62, 65,\n",
      "        54, 53,  1, 67, 54, 54, 51, 64, 60, 68,  8,  1, 57, 58, 68,  1, 70, 63,\n",
      "        52, 61, 54, 68,  1, 65, 70, 62, 65, 54, 53,  1, 65, 50, 52, 60, 68,  0,\n",
      "        65, 70, 63, 60,  1, 55, 50, 60, 54,  8,  1, 59, 70, 62, 65,  9, 68, 57,\n",
      "        64, 69,  8,  1, 51, 50, 61, 61,  1, 57, 58, 69,  1, 69, 57, 54,  1, 51,\n",
      "        50, 52, 60,  0, 51, 50, 61, 61,  1, 53, 67, 54, 50, 62, 68,  1, 64, 55,\n",
      "         1, 51, 54, 58, 63, 56,  1, 65, 64, 58, 63, 69,  1, 56, 70, 50, 67, 53,\n",
      "         1, 72, 50, 68,  1, 64, 55, 55,  1, 61, 58, 62, 58, 69, 68,  1, 59, 50,\n",
      "        52, 60,  0, 69, 57, 50, 69,  5, 68,  1, 51, 54, 52, 50, 70, 68, 54,  1,\n",
      "        69, 57, 54, 68, 54,  1, 52, 64, 62, 65, 69, 64, 63,  1, 68, 69, 67, 54,\n",
      "        54, 69, 68,  1, 72, 50, 68,  1, 51, 70, 58, 61, 69,  1, 63, 64, 69,  1,\n",
      "        69, 64,  1, 72, 58, 63,  0, 74, 64, 70,  1, 60, 58, 61, 61, 54, 53,  1,\n",
      "        69, 57, 54,  1, 63, 58, 56, 56, 50,  8,  1, 58,  1, 68, 69, 64, 61, 54,\n",
      "         1, 50,  1, 51, 58, 51, 61, 54,  8,  1, 58, 68,  1, 69, 57, 50, 69,  1,\n",
      "        50,  1, 68, 58, 63,  0, 65, 50, 67, 69,  1, 64, 55,  1, 62, 54,  1, 69,\n",
      "        57, 64, 70, 56, 57,  8,  1, 58,  5, 62,  1, 68, 54, 50, 67, 52, 57, 58,\n",
      "        63, 56,  1, 55, 64, 67,  1, 50, 63, 68, 72, 54, 67, 68,  1, 59, 70, 68,\n",
      "        69,  1, 68, 54, 50, 67, 52, 57, 58, 63, 56,  1, 55, 64, 67,  1, 69, 57,\n",
      "        54,  1, 65, 54, 67, 55, 54, 52, 69,  1, 68, 57, 64, 69,  0, 69, 57, 54,\n",
      "         1, 56, 64, 64, 53,  1, 60, 58, 53,  1, 55, 67, 64, 62,  1, 69, 57, 54,\n",
      "         1, 70, 56, 61, 74,  1, 52, 58, 69, 74,  1, 69, 57, 50, 69,  5, 68,  1,\n",
      "        62, 50, 53,  1, 69, 57, 50, 69,  1, 57, 54,  5, 68,  1, 57, 50, 53,  1,\n",
      "        68, 64, 62, 54,  0, 72, 57, 54, 67, 54,  1, 58, 68,  1, 69, 57, 54,  1,\n",
      "        61, 64, 71, 54,  0,  0, 72, 57, 54, 63])\n"
     ]
    }
   ],
   "source": [
    "# encode the entire dataset from string to integers\n",
    "import torch\n",
    "\n",
    "data = torch.tensor(encode(lyrics), dtype=torch.long)\n",
    "print(data.shape, data.type)\n",
    "# the first 1000 characters from our dataset converted using our encoder mapping (from str to int)\n",
    "print(data[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create our train and validation datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split 90% of our data into train and have remaining 10% as our validation\n",
    "n = int(0.9 * len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "498658"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55407"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([68, 58, 69,  1, 68, 69, 58, 61, 61])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use block_size / context length interchangeably\n",
    "block_size = 8\n",
    "train_data[: block_size + 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "given a tensor above, there are 8 training examples within a sample of size blocksize. <br>\n",
    "E.g : <br>\n",
    "x = 68 , y = 58 <br>\n",
    "x = [68,58], y = 69 <br>\n",
    "x = [68,58,69] , y = 1 <br>\n",
    "etc until the 8th training example within this sample <br>\n",
    "x = [68,58,69,1,68,69,58,61], y = 61 <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_data[:block_size]\n",
    "# y is technically our target for the input of x, thus it is ofset by 1\n",
    "y = train_data[1 : block_size + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([68, 58, 69,  1, 68, 69, 58, 61])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([58, 69,  1, 68, 69, 58, 61, 61])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when in put is tensor([68]) the target is: 58\n",
      "when in put is tensor([68, 58]) the target is: 69\n",
      "when in put is tensor([68, 58, 69]) the target is: 1\n",
      "when in put is tensor([68, 58, 69,  1]) the target is: 68\n",
      "when in put is tensor([68, 58, 69,  1, 68]) the target is: 69\n",
      "when in put is tensor([68, 58, 69,  1, 68, 69]) the target is: 58\n",
      "when in put is tensor([68, 58, 69,  1, 68, 69, 58]) the target is: 61\n",
      "when in put is tensor([68, 58, 69,  1, 68, 69, 58, 61]) the target is: 61\n"
     ]
    }
   ],
   "source": [
    "for t in range(block_size):\n",
    "    context = x[: t + 1]\n",
    "    target = y[t]\n",
    "    print(f\"when in put is {context} the target is: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "batch_size = 4  # how many independent sequences will we process in parallel\n",
    "block_size = 8  # what is the maximum context length for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(split):\n",
    "    # generate a small batch of data for inputs x and targets y\n",
    "    data = train_data if split == \"train\" else val_data\n",
    "\n",
    "    # generate a tensor of random integers, that represent the starting position of each sequence of data\n",
    "    batch_start_indicies = torch.randint(high=(len(data) - block_size), size=(batch_size,))\n",
    "\n",
    "    # creates a tensor: x and y where each element is a sequence of block_size, stack the 1-D tensors as rows\n",
    "    # creating a batch_size x block_size tensors (e.g 4x8 tensor)\n",
    "    x = torch.stack([data[index : index + block_size] for index in batch_start_indicies])\n",
    "    y = torch.stack([data[index + 1 : index + block_size + 1] for index in batch_start_indicies])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size = 4 \n",
      "Block size = 8 \n",
      "\n",
      "inputs: \n",
      "torch.Size([4, 8])\n",
      "tensor([[58, 52, 57,  1, 63, 58, 56, 56],\n",
      "        [64, 72,  1, 59, 70, 68, 69,  1],\n",
      "        [55, 70, 52, 60, 58, 63,  5,  1],\n",
      "        [32,  5, 62,  1, 51, 61, 54, 68]]) \n",
      "\n",
      "targets: \n",
      "torch.Size([4, 8])\n",
      "tensor([[52, 57,  1, 63, 58, 56, 56, 50],\n",
      "        [72,  1, 59, 70, 68, 69,  1, 72],\n",
      "        [70, 52, 60, 58, 63,  5,  1, 62],\n",
      "        [ 5, 62,  1, 51, 61, 54, 68, 68]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "xb, yb = get_batch('train')\n",
    "print(f\"Batch size = {batch_size} \\nBlock size = {block_size} \\n\")\n",
    "\n",
    "print('inputs: ')\n",
    "print(xb.shape)\n",
    "print(xb, '\\n')\n",
    "\n",
    "print('targets: ')\n",
    "print(yb.shape)\n",
    "print(yb, '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When input is [58] the target is 52\n",
      "When input is [58, 52] the target is 57\n",
      "When input is [58, 52, 57] the target is 1\n",
      "When input is [58, 52, 57, 1] the target is 63\n",
      "When input is [58, 52, 57, 1, 63] the target is 58\n",
      "When input is [58, 52, 57, 1, 63, 58] the target is 56\n",
      "When input is [58, 52, 57, 1, 63, 58, 56] the target is 56\n",
      "When input is [58, 52, 57, 1, 63, 58, 56, 56] the target is 50\n",
      "\n",
      "\n",
      "When input is [64] the target is 72\n",
      "When input is [64, 72] the target is 1\n",
      "When input is [64, 72, 1] the target is 59\n",
      "When input is [64, 72, 1, 59] the target is 70\n",
      "When input is [64, 72, 1, 59, 70] the target is 68\n",
      "When input is [64, 72, 1, 59, 70, 68] the target is 69\n",
      "When input is [64, 72, 1, 59, 70, 68, 69] the target is 1\n",
      "When input is [64, 72, 1, 59, 70, 68, 69, 1] the target is 72\n",
      "\n",
      "\n",
      "When input is [55] the target is 70\n",
      "When input is [55, 70] the target is 52\n",
      "When input is [55, 70, 52] the target is 60\n",
      "When input is [55, 70, 52, 60] the target is 58\n",
      "When input is [55, 70, 52, 60, 58] the target is 63\n",
      "When input is [55, 70, 52, 60, 58, 63] the target is 5\n",
      "When input is [55, 70, 52, 60, 58, 63, 5] the target is 1\n",
      "When input is [55, 70, 52, 60, 58, 63, 5, 1] the target is 62\n",
      "\n",
      "\n",
      "When input is [32] the target is 5\n",
      "When input is [32, 5] the target is 62\n",
      "When input is [32, 5, 62] the target is 1\n",
      "When input is [32, 5, 62, 1] the target is 51\n",
      "When input is [32, 5, 62, 1, 51] the target is 61\n",
      "When input is [32, 5, 62, 1, 51, 61] the target is 54\n",
      "When input is [32, 5, 62, 1, 51, 61, 54] the target is 68\n",
      "When input is [32, 5, 62, 1, 51, 61, 54, 68] the target is 68\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for b in range(batch_size): # iterate through the batch dimension (batches)\n",
    "    for t in range(block_size): # iterate through the time dimension (each character/element/number in the batch)\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b,t]\n",
    "        print(f\"When input is {context.tolist()} the target is {target}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our 4x8 tensor contains 32 training examples, which are completely independent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[58, 52, 57,  1, 63, 58, 56, 56],\n",
       "        [64, 72,  1, 59, 70, 68, 69,  1],\n",
       "        [55, 70, 52, 60, 58, 63,  5,  1],\n",
       "        [32,  5, 62,  1, 51, 61, 54, 68]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# our input to the transformer \n",
    "xb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        # maps each token in the sequence to its next-token prediction in the form of logits\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        # idx and targets are both (B,T) tensors of integers\n",
    "        logits = self.token_embedding_table(\n",
    "            idx\n",
    "        )  # (B,T,C) , where C = channel = vocab size\n",
    "\n",
    "        if targets is None:\n",
    "            # if no target, just get the logits\n",
    "            loss = None\n",
    "        else:\n",
    "            # since we have a multi-dimensional input, PyTorch cross_entropy function expects the logit tensor shape to be (B*T,C) and not (B,T,C)\n",
    "            # and the target tensor to be 1D. Therefore we have to reshape our logit and target tensors\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B * T, C) # want it to be 2-D Tensor\n",
    "            targets = targets.view(B*T)  # want it to be 1-D Tensor\n",
    "\n",
    "            # measures the quality of the logits w.r.t the targets,\n",
    "            # how well are we predicting the next character based on the logits\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B,T) tensor of indicies in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # get predictions\n",
    "            logits, loss = self(idx)\n",
    "            # only consider last element in the time dimension, becomes (B,C)\n",
    "            logits = logits[:,-1,:] \n",
    "            # apply softmax to get proababilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B,C)\n",
    "            # sample from the distribution, only gets 1 prediction so becomes (B,1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BigramLanguageModel(vocab_size=vocab_size)\n",
    "logits, loss = model(xb,yb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 86])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.9753, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we are expecting a loss of -ln(1/vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We expect the loss to be about 4.454347296253507\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from math import log\n",
    "print(f\"We expect the loss to be about {-log(1/vocab_size)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "í–v L'szïU.е7/bR\n",
      "Z1g6'sl)HwPp(–\"âXo//Dâ?JIwNGqígàl(ZéG-YY4a6A9е,Oú–CàKJ3\")LNkm1é9ASpL/qKJk/D(WdfB234\n"
     ]
    }
   ],
   "source": [
    "idx = torch.zeros((1, 1), dtype=torch.long)\n",
    "\n",
    "print(decode(model.generate(idx, max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generated output is random because our model hasnt been trained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intialise optimiser\n",
    "optimiser = torch.optim.AdamW(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.471187114715576\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for steps in range(10000):\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate loss\n",
    "    logits, loss = model(xb,yb)\n",
    "    optimiser.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimiser.step()\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "te yof is theaYSAl(Msin ache fomancenet'mery gand l n boucanarr g, m\n",
      "\n",
      "iedole\n",
      "i g m g, bul e\n",
      "id sithe joren ccr sthandovorlorall\n",
      "iman ly ait t, me mp, m ite intul me, bl tcourinck\n",
      "but my, tot jus bas a tht h m ton'm t icillundy gil daroma juc gif, as\n",
      "atinith a t bewery dediali wheambugumy zis tien'sthatheretherkel wige itanndpeledorigen wi-Rt hemine RUpodbr c mey hino aut peg ithed a lor, gachortin ilache, piler o\n",
      "An'aixts buloon, thur o hearomyolala yontwathtoverbeen dne t anke?44\n",
      "titr bean'myou\n"
     ]
    }
   ],
   "source": [
    "idx = torch.zeros((1, 1), dtype=torch.long)\n",
    "\n",
    "print(decode(model.generate(idx, max_new_tokens=500)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix multiplication in self-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example 1: inefficient method using loops \n",
    "torch.manual_seed(42)\n",
    "# Batch, time, channels\n",
    "B,T,C = 4,8,2\n",
    "x = torch.randn(B,T,C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bow = bag of words\n",
    "xbow = torch.zeros((B,T,C))\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b, :t+1] # (t,C) tensor\n",
    "        xbow[b,t] = torch.mean(xprev, dim = 0) # averaging out on the t-dimension , to get 1D C-vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.9269,  1.4873],\n",
       "        [ 0.9007, -2.1055],\n",
       "        [ 0.6784, -1.2345],\n",
       "        [-0.0431, -1.6047],\n",
       "        [-0.7521,  1.6487],\n",
       "        [-0.3925, -1.4036],\n",
       "        [-0.7279, -0.5594],\n",
       "        [-0.7688,  0.7624]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0th batch element\n",
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.9269,  1.4873],\n",
       "        [ 1.4138, -0.3091],\n",
       "        [ 1.1687, -0.6176],\n",
       "        [ 0.8657, -0.8644],\n",
       "        [ 0.5422, -0.3617],\n",
       "        [ 0.3864, -0.5354],\n",
       "        [ 0.2272, -0.5388],\n",
       "        [ 0.1027, -0.3762]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow[0]\n",
    "# we can see that as we iterate over the t-dimensino each value is an average with the previous values e.g the at t = 8, the 2 values in the vector\n",
    "# are the average down the column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using loops to calculate our running averages across the t-dimension is inefficient , especially as our tensors get bigger. We can use matrix multiplciation to speed up this calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "b=\n",
      "tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]]) \n",
      "\n",
      "c=\n",
      "tensor([[14., 16.],\n",
      "        [14., 16.],\n",
      "        [14., 16.]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# example 2: using matrix multiplcation\n",
    "torch.manual_seed(42)\n",
    "a = torch.ones(3, 3)\n",
    "b = torch.randint(0, 10, (3, 2)).float()\n",
    "c = a @ b\n",
    "\n",
    "print(\"a=\")\n",
    "print(a, \"\\n\")\n",
    "print(\"b=\")\n",
    "print(b, \"\\n\")\n",
    "print(\"c=\")\n",
    "print(c, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [1., 1., 0.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use torch.tril to createa a lower triangular matrix of size nxn, we will be using this to make sure the future tokens do not interact with the past tokens as we are trying to predict the future tokens\n",
    "torch.tril(torch.ones(3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=\n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]]) \n",
      "\n",
      "b=\n",
      "tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]]) \n",
      "\n",
      "c=\n",
      "tensor([[2.0000, 7.0000],\n",
      "        [4.0000, 5.5000],\n",
      "        [4.6667, 5.3333]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "a = torch.tril(torch.ones(3, 3))\n",
    "# normalise the rows and make each row sum to 1. Lets us calculate the average of each row.\n",
    "a = a / torch.sum(a, dim=1, keepdim=True)\n",
    "b = torch.randint(0, 10, (3, 2)).float()\n",
    "c = a @ b\n",
    "\n",
    "print(\"a=\")\n",
    "print(a, \"\\n\")\n",
    "print(\"b=\")\n",
    "print(b, \"\\n\")\n",
    "print(\"c=\")\n",
    "print(c, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
       "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
       "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create our xbow using matrix multiplication\n",
    "weights = torch.tril(torch.ones(T,T))\n",
    "weights = weights / weights.sum(dim=1, keepdim=True)\n",
    "# our \"weights-tensor\" would be equivalent to our \"a-tensor\" in the example above, our \"b-tensor\" would be \"x-tensor\"\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow2 = weights @ x # weights = (T,T) @ x = (B,T,C) --> PyTorch will create a batch-dimension in weights tensor to be (B,T,T) and then after batched matrix-mult of (B,T,T) @ (B,T,C) ==> (B,T,C)\n",
    "xbow2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.9269,  1.4873],\n",
       "        [ 1.4138, -0.3091],\n",
       "        [ 1.1687, -0.6176],\n",
       "        [ 0.8657, -0.8644],\n",
       "        [ 0.5422, -0.3617],\n",
       "        [ 0.3864, -0.5354],\n",
       "        [ 0.2272, -0.5388],\n",
       "        [ 0.1027, -0.3762]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(xbow,xbow2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.9269,  1.4873],\n",
       "         [ 1.4138, -0.3091],\n",
       "         [ 1.1687, -0.6176],\n",
       "         [ 0.8657, -0.8644],\n",
       "         [ 0.5422, -0.3617],\n",
       "         [ 0.3864, -0.5354],\n",
       "         [ 0.2272, -0.5388],\n",
       "         [ 0.1027, -0.3762]]),\n",
       " tensor([[ 1.9269,  1.4873],\n",
       "         [ 1.4138, -0.3091],\n",
       "         [ 1.1687, -0.6176],\n",
       "         [ 0.8657, -0.8644],\n",
       "         [ 0.5422, -0.3617],\n",
       "         [ 0.3864, -0.5354],\n",
       "         [ 0.2272, -0.5388],\n",
       "         [ 0.1027, -0.3762]]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow[0], xbow2[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see that xbow2 is identical to xbow but we used a more efficient method of using batched matrix-multiplcation instead of loops to compute the tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example 3 :  with softmax\n",
    "tril = torch.tril(torch.ones((T,T)))\n",
    "tril"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = torch.zeros((T,T))\n",
    "weights = weights.masked_fill(tril == 0, float('-inf'))\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.9269,  1.4873],\n",
       "        [ 1.4138, -0.3091],\n",
       "        [ 1.1687, -0.6176],\n",
       "        [ 0.8657, -0.8644],\n",
       "        [ 0.5422, -0.3617],\n",
       "        [ 0.3864, -0.5354],\n",
       "        [ 0.2272, -0.5388],\n",
       "        [ 0.1027, -0.3762]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = F.softmax(weights, dim=-1)\n",
    "# softmax exponentiates values, e^0 = 1, and e^-inf = 0, useful for when our weights are data dependent and not statically made\n",
    "xbow3 = weights @ x\n",
    "xbow3[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(xbow,xbow3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "summary of this section : we can do weighted aggregations of our past elements by using matrix multiplciation of a lower triangular matrix, elements in the lower triangle are how much the words relate to each other"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
